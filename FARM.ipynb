{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import threading\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "import gc\n",
    "import mxnet as mx\n",
    "from mxnet import nd\n",
    "from mxnet import gluon\n",
    "from mxnet import init\n",
    "from mxnet import autograd\n",
    "%matplotlib inline\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['MXNET_GPU_MEM_POOL_RESERVE'] = '25'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "mx.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def try_gpu():\n",
    "    try:\n",
    "        ctx = mx.gpu()\n",
    "        _ = nd.array([0], ctx=ctx)\n",
    "    except:\n",
    "        ctx = mx.cpu()\n",
    "    return ctx\n",
    "ctx = try_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_vocab(path):\n",
    "    filelist = ['type.dat','color.dat','material.dat','model.dat','pattern.dat','style.dat','position.dat']\n",
    "    word_vocab = {}\n",
    "    index_vocab = {}\n",
    "    index = 0\n",
    "    for file in filelist:\n",
    "        with open(path+file,'r',encoding='utf-8') as f:\n",
    "            content = f.readlines()\n",
    "        for line in content:\n",
    "            line = line[:-1].split()\n",
    "            for word in line:\n",
    "                word_vocab[word] = index\n",
    "            index_vocab[index] = line\n",
    "            index += 1\n",
    "        del content\n",
    "    return word_vocab, index_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_itemlist(path, word_vocab):\n",
    "    with open(path,'r',encoding='utf-8') as f:\n",
    "        content = f.readlines()\n",
    "    itemlist = {}\n",
    "    for line in content:\n",
    "        line = line[:-1].split('\\t')\n",
    "        item = line[0]\n",
    "        description = line[1]\n",
    "        combination = set(line[2].split('|'))\n",
    "        itemlist[item] = {'description':description,'combination':combination}\n",
    "        del line\n",
    "    del content\n",
    "    return itemlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_descriptionlist(path, word_vocab, vocab_size):\n",
    "    with open(path,'r',encoding='utf-8') as f:\n",
    "        content = f.readlines()\n",
    "    descriptionlist = {}\n",
    "    for line in content:\n",
    "        line = line[:-1].split('\\t')\n",
    "        id = line[0]\n",
    "        text = line[1]\n",
    "        items = set(line[2].split('|'))\n",
    "        vector = np.zeros(vocab_size)\n",
    "        for word in text.split(' '):\n",
    "            if word in word_vocab:\n",
    "                vector[word_vocab[word]] = 1\n",
    "        descriptionlist[id] = {'vector':vector,'text':text,'items':items}\n",
    "        del line,vector\n",
    "    del content\n",
    "    return descriptionlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class myThread (threading.Thread):\n",
    "    def __init__(self, imglist, img_idxs):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.imglist = imglist\n",
    "        self.img_idxs = img_idxs\n",
    "    def run(self): \n",
    "        for img_idx in self.img_idxs:\n",
    "            img = Image.open('img/'+img_idx+'.jpg')\n",
    "            img = np.array(img)\n",
    "            img = img/255.0\n",
    "            img = img.transpose([2,0,1])\n",
    "            self.imglist[img_idx] = img\n",
    "            del img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'dataset/vocab/'\n",
    "word_vocab,index_vocab = read_vocab(path)\n",
    "len(index_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'dataset/toplist.dat'\n",
    "toplist = read_itemlist(path, word_vocab)\n",
    "alltops = list(toplist.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'dataset/bottomlist.dat'\n",
    "bottomlist = read_itemlist(path, word_vocab)\n",
    "allbottoms = list(bottomlist.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'dataset/descriptionlist.dat'\n",
    "descriptionlist = read_descriptionlist(path, word_vocab, len(index_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imglist = {}\n",
    "tops = random.sample(alltops,50000)\n",
    "bottoms = random.sample(allbottoms,50000)\n",
    "threads = []\n",
    "thread1 = myThread(imglist,tops[:len(tops)//2])\n",
    "thread2 = myThread(imglist,tops[len(tops)//2:])\n",
    "thread3 = myThread(imglist,bottoms[:len(bottoms)//2])\n",
    "thread4 = myThread(imglist,bottoms[len(bottoms)//2:])\n",
    "thread1.start()\n",
    "thread2.start()\n",
    "thread3.start()\n",
    "thread4.start()\n",
    "threads.append(thread1)\n",
    "threads.append(thread2)\n",
    "threads.append(thread3)\n",
    "threads.append(thread4)\n",
    "for t in threads:\n",
    "    t.join()\n",
    "print(len(imglist)==len(tops)+len(bottoms))\n",
    "del threads,tops,bottoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outfitlist = {}\n",
    "with open('dataset/outfitlist.dat','r',encoding='utf-8') as f:\n",
    "    content = f.readlines()\n",
    "for line in content:\n",
    "    line = line[:-1].split('\\t')\n",
    "    top = line[0]\n",
    "    description = line[1]\n",
    "    bottoms = line[2].split('|')\n",
    "    outfitlist[(top,description)] = set(bottoms)\n",
    "    del line\n",
    "del content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = []\n",
    "with open('dataset/traindata.dat','r',encoding='utf-8') as f:\n",
    "    content = f.readlines()\n",
    "for line in content:\n",
    "    line = line[:-1].split('\\t')\n",
    "    top = line[0]\n",
    "    description = line[1]\n",
    "    bottoms = line[2].split('|')\n",
    "    for bottom in bottoms:\n",
    "        train_data.append((top,description,bottom))\n",
    "    del line\n",
    "del content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_data = {}\n",
    "with open('dataset/validdata.dat','r',encoding='utf-8') as f:\n",
    "    content = f.readlines()\n",
    "for line in content:\n",
    "    line = line[:-1].split('\\t')\n",
    "    top = line[0]\n",
    "    description = line[1]\n",
    "    bottom = line[2]\n",
    "    negatives = line[3].split('|')\n",
    "    valid_data[(top,description,bottom)] = negatives\n",
    "    del line\n",
    "del content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = {}\n",
    "with open('dataset/testdata.dat','r',encoding='utf-8') as f:\n",
    "    content = f.readlines()\n",
    "for line in content:\n",
    "    line = line[:-1].split('\\t')\n",
    "    top = line[0]\n",
    "    description = line[1]\n",
    "    bottom = line[2]\n",
    "    negatives = line[3].split('|')\n",
    "    test_data[(top,description,bottom)] = negatives\n",
    "    del line\n",
    "del content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SRResNetBlock(gluon.nn.Block):\n",
    "    def __init__(self, channels, same_shape=True, **kwargs):\n",
    "        super(SRResNetBlock, self).__init__(**kwargs)\n",
    "        self.same_shape = same_shape\n",
    "        strides = 1 if same_shape else 2\n",
    "        self.conv1 = gluon.nn.Conv2D(channels, kernel_size=3, padding=1, strides=strides)\n",
    "        self.conv2 = gluon.nn.Conv2D(channels, kernel_size=3, padding=1)\n",
    "        if not same_shape:\n",
    "            self.conv3 = gluon.nn.Conv2D(channels, kernel_size=1, strides=strides)\n",
    "        self.bn1 = gluon.nn.BatchNorm()\n",
    "        self.bn2 = gluon.nn.BatchNorm()\n",
    "    def forward(self, x):\n",
    "        out = nd.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        if not self.same_shape:\n",
    "            x = self.conv3(x)\n",
    "        return out+x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class farm_top_encoder(gluon.nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(farm_top_encoder, self).__init__(**kwargs) \n",
    "        self.convs = gluon.nn.Sequential()\n",
    "        self.convs.add(\n",
    "            gluon.nn.Conv2D(channels=64, kernel_size=4, strides=2, padding=1),#64*64*64\n",
    "            gluon.nn.BatchNorm(),\n",
    "            gluon.nn.Activation('relu'),\n",
    "            gluon.nn.Conv2D(channels=128, kernel_size=4, strides=2, padding=1),#128*32*32\n",
    "            gluon.nn.BatchNorm(),\n",
    "            gluon.nn.Activation('relu'),\n",
    "            gluon.nn.Conv2D(channels=256, kernel_size=4, strides=2, padding=1),#256*16*16\n",
    "            gluon.nn.BatchNorm(),\n",
    "            gluon.nn.Activation('relu'),\n",
    "            gluon.nn.Conv2D(channels=512, kernel_size=4, strides=2, padding=1),#512*8*8\n",
    "            gluon.nn.BatchNorm(),\n",
    "            gluon.nn.Activation('relu'),\n",
    "            gluon.nn.Conv2D(channels=512, kernel_size=4, strides=2, padding=1),#512*4*4\n",
    "            gluon.nn.BatchNorm(),\n",
    "            gluon.nn.Activation('relu'),\n",
    "            gluon.nn.Conv2D(channels=1024, kernel_size=4, strides=1, padding=0),#1024*1*1\n",
    "            gluon.nn.BatchNorm(),\n",
    "            gluon.nn.Activation('relu'),\n",
    "            gluon.nn.Flatten(),#1024\n",
    "            gluon.nn.Dropout(0.5),\n",
    "            gluon.nn.Dense(100, activation='sigmoid')\n",
    "        )\n",
    "    def forward(self, img):\n",
    "        enc = self.convs(img)\n",
    "        return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class farm_bottom_encoder(gluon.nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(farm_bottom_encoder, self).__init__(**kwargs) \n",
    "        self.convs_1 = gluon.nn.Sequential()\n",
    "        self.convs_1.add(\n",
    "            gluon.nn.Conv2D(channels=64, kernel_size=4, strides=2, padding=1),#64*64*64\n",
    "            gluon.nn.BatchNorm(),\n",
    "            gluon.nn.Activation('relu'),\n",
    "            gluon.nn.Conv2D(channels=128, kernel_size=4, strides=2, padding=1),#128*32*32\n",
    "            gluon.nn.BatchNorm(),\n",
    "            gluon.nn.Activation('relu'),\n",
    "            gluon.nn.Conv2D(channels=256, kernel_size=4, strides=2, padding=1),#256*16*16\n",
    "            gluon.nn.BatchNorm(),\n",
    "            gluon.nn.Activation('relu'),\n",
    "            gluon.nn.Conv2D(channels=512, kernel_size=4, strides=2, padding=1),#512*8*8\n",
    "            gluon.nn.BatchNorm(),\n",
    "            gluon.nn.Activation('relu')\n",
    "        )\n",
    "        self.feature_3 = gluon.nn.Sequential()\n",
    "        self.feature_3.add(\n",
    "            gluon.nn.GlobalAvgPool2D(),#[batch_size,512,1,1]\n",
    "            gluon.nn.Flatten(),#[batch_size,512]\n",
    "            gluon.nn.Dense(100, activation='sigmoid') \n",
    "        )\n",
    "        self.convs_2 = gluon.nn.Sequential()\n",
    "        self.convs_2.add(\n",
    "            gluon.nn.Conv2D(channels=512, kernel_size=4, strides=2, padding=1),#512*4*4\n",
    "            gluon.nn.BatchNorm(),\n",
    "            gluon.nn.Activation('relu')\n",
    "        )\n",
    "        self.feature_2 = gluon.nn.Sequential()\n",
    "        self.feature_2.add(\n",
    "            gluon.nn.GlobalAvgPool2D(),#[batch_size,512,1,1]\n",
    "            gluon.nn.Flatten(),#[batch_size,512]\n",
    "            gluon.nn.Dense(100, activation='sigmoid') \n",
    "        )\n",
    "        self.convs_3 = gluon.nn.Sequential()\n",
    "        self.convs_3.add(\n",
    "            gluon.nn.Conv2D(channels=1024, kernel_size=4, strides=1, padding=0),#1024*1*1\n",
    "            gluon.nn.BatchNorm(),\n",
    "            gluon.nn.Activation('relu'),\n",
    "            gluon.nn.Flatten()#[batch_size,1024]\n",
    "        )\n",
    "        self.feature_1 = gluon.nn.Sequential()\n",
    "        self.feature_1.add(\n",
    "            gluon.nn.Dense(100, activation='sigmoid') \n",
    "        )      \n",
    "        self.dropout = gluon.nn.Dropout(0.5)\n",
    "        self.dense = gluon.nn.Dense(100, activation='sigmoid')\n",
    "    def forward(self, img):\n",
    "        enc = self.convs_1(img)\n",
    "        feature_3 = self.feature_3(enc)\n",
    "        enc = self.convs_2(enc)\n",
    "        feature_2 = self.feature_2(enc)\n",
    "        enc = self.convs_3(enc)\n",
    "        feature_1 = self.feature_1(enc)     \n",
    "        enc = self.dropout(enc)\n",
    "        enc = self.dense(enc)\n",
    "        return enc, feature_1, feature_2, feature_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class farm_transformer(gluon.nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(farm_transformer, self).__init__(**kwargs)     \n",
    "        self.dense_1 = gluon.nn.Dense(100)\n",
    "        self.dense_2 = gluon.nn.Dense(100)\n",
    "    def forward(self, enc_x, enc_c):\n",
    "        con = nd.concat(enc_x, enc_c, dim=1)\n",
    "        z_mean = self.dense_1(con)\n",
    "        z_log_var = self.dense_2(con)\n",
    "        epsilon = nd.random_normal(loc=0, scale=1, shape=z_mean.shape, ctx=ctx)\n",
    "        z = z_mean+nd.exp(0.5*z_log_var)*epsilon\n",
    "        return z,z_mean,z_log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class farm_generator(gluon.nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(farm_generator, self).__init__(**kwargs)\n",
    "        self.seq = gluon.nn.Sequential()\n",
    "        self.seq.add(\n",
    "            gluon.nn.Dense(1024),\n",
    "            gluon.nn.BatchNorm(),\n",
    "            gluon.nn.Activation('relu')\n",
    "        )\n",
    "        self.feature_1 = gluon.nn.Sequential()\n",
    "        self.feature_1.add(\n",
    "            gluon.nn.Dense(100, activation='sigmoid')\n",
    "        )\n",
    "        self.convs_1 = gluon.nn.Sequential()\n",
    "        self.convs_1.add(\n",
    "            gluon.nn.Conv2DTranspose(channels=512, kernel_size=4, strides=1, padding=0),#512*4*4\n",
    "            gluon.nn.BatchNorm(),\n",
    "            gluon.nn.Activation('relu')\n",
    "        )\n",
    "        self.feature_2 = gluon.nn.Sequential()\n",
    "        self.feature_2.add(\n",
    "            gluon.nn.GlobalAvgPool2D(),#[batch_size,512,1,1]\n",
    "            gluon.nn.Flatten(),#[batch_size,512]\n",
    "            gluon.nn.Dense(100, activation='sigmoid')\n",
    "        )\n",
    "        self.convs_2 = gluon.nn.Sequential()\n",
    "        self.convs_2.add(\n",
    "            gluon.nn.Conv2DTranspose(channels=512, kernel_size=4, strides=2, padding=1),#512*8*8\n",
    "            gluon.nn.BatchNorm(),\n",
    "            gluon.nn.Activation('relu')\n",
    "        )\n",
    "        self.feature_3 = gluon.nn.Sequential()\n",
    "        self.feature_3.add(\n",
    "            gluon.nn.GlobalAvgPool2D(),#[batch_size,512,1,1]\n",
    "            gluon.nn.Flatten(),#[batch_size,512]\n",
    "            gluon.nn.Dense(100, activation='sigmoid')\n",
    "        )\n",
    "        self.convs_3 = gluon.nn.Sequential()\n",
    "        self.convs_3.add(\n",
    "            gluon.nn.Conv2DTranspose(channels=256, kernel_size=4, strides=2, padding=1),#256*16*16\n",
    "            gluon.nn.BatchNorm(),\n",
    "            gluon.nn.Activation('relu'),\n",
    "            gluon.nn.Conv2DTranspose(channels=128, kernel_size=4, strides=2, padding=1),#128*32*32\n",
    "            gluon.nn.BatchNorm(),\n",
    "            gluon.nn.Activation('relu'),\n",
    "            gluon.nn.Conv2DTranspose(channels=64, kernel_size=4, strides=2, padding=1),#64*64*64\n",
    "            gluon.nn.BatchNorm(),\n",
    "            gluon.nn.Activation('relu'),\n",
    "            gluon.nn.Conv2DTranspose(channels=3, kernel_size=4, strides=2, padding=1),#3*128*128\n",
    "            gluon.nn.Activation('sigmoid')\n",
    "        )\n",
    "        self.convs_4 = gluon.nn.Sequential()\n",
    "        self.convs_4.add(\n",
    "            gluon.nn.Conv2D(channels=32, kernel_size=3, strides=1, padding=1),#32*128*128\n",
    "            gluon.nn.BatchNorm(),\n",
    "            gluon.nn.Activation('relu')\n",
    "        )\n",
    "        self.convs_5 = gluon.nn.Sequential()\n",
    "        self.convs_5.add(\n",
    "            SRResNetBlock(32),\n",
    "            SRResNetBlock(32),\n",
    "            SRResNetBlock(32),\n",
    "            gluon.nn.Conv2D(channels=32, kernel_size=3, strides=1, padding=1),#32*128*128\n",
    "            gluon.nn.BatchNorm(),\n",
    "            gluon.nn.Activation('relu')\n",
    "        )\n",
    "        self.convs_6 = gluon.nn.Sequential()\n",
    "        self.convs_6.add(\n",
    "            gluon.nn.Conv2D(channels=3, kernel_size=1, strides=1, padding=0),#3*128*128\n",
    "            gluon.nn.Activation('sigmoid')\n",
    "        )\n",
    "    def forward(self, z, enc_x, enc_c):\n",
    "        dec = nd.concat(z, enc_x, enc_c, dim=1)\n",
    "        dec = self.seq(dec)#[batch_size,1024]  \n",
    "        feature_1 = self.feature_1(dec)\n",
    "        dec = dec.reshape(shape=(dec.shape[0], 1024, 1, 1))#1024*1*1\n",
    "        dec = self.convs_1(dec)\n",
    "        feature_2 = self.feature_2(dec)\n",
    "        dec = self.convs_2(dec)\n",
    "        feature_3 = self.feature_3(dec)\n",
    "        y_rec_low = self.convs_3(dec)\n",
    "        low_to_high_1 = self.convs_4(y_rec_low)\n",
    "        low_to_high_2 = self.convs_5(low_to_high_1)\n",
    "        y_rec_high = self.convs_6(low_to_high_1+low_to_high_2)\n",
    "        return y_rec_low, y_rec_high, feature_1, feature_2, feature_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class farm_recommender(gluon.nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(farm_recommender, self).__init__(**kwargs)\n",
    "    def forward(self, enc_x, enc_c, enc_yp, enc_yn, feature_1_yp, feature_2_yp, feature_3_yp, feature_1_yn, feature_2_yn, feature_3_yn, feature_1_yg, feature_2_yg, feature_3_yg):\n",
    "        score_yp = nd.sum(enc_yp*enc_x, axis=1)+nd.sum(enc_yp*enc_c, axis=1)+nd.sum(feature_1_yp*feature_1_yg, axis=1)+nd.sum(feature_2_yp*feature_2_yg, axis=1)+nd.sum(feature_3_yp*feature_3_yg, axis=1)\n",
    "        score_yn = nd.sum(enc_yn*enc_x, axis=1)+nd.sum(enc_yn*enc_c, axis=1)+nd.sum(feature_1_yn*feature_1_yg, axis=1)+nd.sum(feature_2_yn*feature_2_yg, axis=1)+nd.sum(feature_3_yn*feature_3_yg, axis=1)\n",
    "        difference_pn = score_yp-score_yn\n",
    "        return difference_pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class farm(gluon.nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(farm, self).__init__(**kwargs)\n",
    "        self.description_embedding = gluon.nn.Dense(100, activation='sigmoid')\n",
    "        self.top_encoder = farm_top_encoder()\n",
    "        self.bottom_encoder = farm_bottom_encoder()\n",
    "        self.transformer = farm_transformer()\n",
    "        self.generator = farm_generator()\n",
    "        self.recommender = farm_recommender()\n",
    "    def forward(self, top_img, bottom_img, negative_img, bottom_description, bottom_description_drop, phase):\n",
    "        enc_c = self.description_embedding(bottom_description)\n",
    "        enc_c_drop = self.description_embedding(bottom_description_drop)\n",
    "        enc_x = self.top_encoder(top_img)\n",
    "        enc_yp, feature_1_yp, feature_2_yp, feature_3_yp = self.bottom_encoder(bottom_img)\n",
    "        enc_yn, feature_1_yn, feature_2_yn, feature_3_yn = self.bottom_encoder(negative_img)\n",
    "        z,z_mean,z_log_var = self.transformer(enc_x, enc_c_drop)\n",
    "        if phase == 'train':\n",
    "            y_rec_low, y_rec_high, feature_1_yg, feature_2_yg, feature_3_yg = self.generator(z, enc_x, enc_c_drop)\n",
    "        if phase == 'test':\n",
    "            y_rec_low, y_rec_high, feature_1_yg, feature_2_yg, feature_3_yg = self.generator(z_mean, enc_x, enc_c_drop)\n",
    "        difference_pn = self.recommender(enc_x, enc_c, enc_yp, enc_yn, feature_1_yp, feature_2_yp, feature_3_yp, feature_1_yn, feature_2_yn, feature_3_yn, feature_1_yg, feature_2_yg, feature_3_yg) \n",
    "        return y_rec_low, y_rec_high, difference_pn, z_mean, z_log_var#, feature_1_yp, feature_2_yp, feature_3_yp, feature_1_yn, feature_2_yn, feature_3_yn, feature_1_yg, feature_2_yg, feature_3_yg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l2loss = gluon.loss.L2Loss()\n",
    "l1loss = gluon.loss.L1Loss()\n",
    "def loss(y, y_rec_low, y_rec_high, difference_pn, z_mean, z_log_var, l2loss, l1loss):\n",
    "    rec_loss = nd.sum(y.shape[1]*y.shape[2]*y.shape[3]*l2loss(y,y_rec_low))+nd.sum(y.shape[1]*y.shape[2]*y.shape[3]*l1loss(y,y_rec_high))  \n",
    "    kl_loss = nd.sum(-0.5*nd.sum(1+z_log_var-nd.square(z_mean)-nd.exp(z_log_var), axis=-1))\n",
    "    bpr_loss = nd.sum(-nd.log(nd.sigmoid(difference_pn)))\n",
    "    loss = rec_loss+kl_loss+bpr_loss\n",
    "    return loss, bpr_loss, rec_loss+kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_img(img_idx,imglist):\n",
    "    if img_idx in imglist:\n",
    "        return imglist[img_idx]\n",
    "    else:\n",
    "        imglist.popitem()\n",
    "        img = Image.open('img/'+img_idx+'.jpg')\n",
    "        img = np.array(img)\n",
    "        img = img/255.0\n",
    "        img = img.transpose([2,0,1])\n",
    "        imglist[img_idx] = img\n",
    "        del img\n",
    "        return imglist[img_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def negative_sample(top, description, outfitlist, allbottoms):\n",
    "    bottoms = outfitlist[(top, description)]\n",
    "    while True:\n",
    "        bottom = random.sample(allbottoms,1)[0]\n",
    "        if bottom not in bottoms:\n",
    "            return bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def description_dropout(description, keep_rate):\n",
    "    if keep_rate < 1.0:\n",
    "        filter = np.random.uniform(low=0.0, high=1.0, size=description.shape) < keep_rate\n",
    "        return description*filter\n",
    "    else:\n",
    "        return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_to_input(batch, imglist, descriptionlist, outfitlist, allbottoms, ctx, keep_rate):\n",
    "    top_img = []\n",
    "    bottom_img = []\n",
    "    bottom_description = []\n",
    "    bottom_description_drop = []\n",
    "    negative_img = []\n",
    "    for instance in batch:\n",
    "        top_img.append(get_img(instance[0], imglist))\n",
    "        bottom_img.append(get_img(instance[2], imglist))\n",
    "        bottom_description.append(descriptionlist[instance[1]]['vector'])\n",
    "        bottom_description_drop.append(description_dropout(descriptionlist[instance[1]]['vector'], keep_rate))\n",
    "        negative_img.append(get_img(negative_sample(instance[0], instance[1], outfitlist, allbottoms), imglist))\n",
    "    top_img_mx = nd.array(top_img, ctx=ctx)\n",
    "    bottom_img_mx = nd.array(bottom_img, ctx=ctx)\n",
    "    bottom_description_mx = nd.array(bottom_description, ctx=ctx)\n",
    "    bottom_description_drop_mx = nd.array(bottom_description_drop, ctx=ctx)\n",
    "    negative_img_mx = nd.array(negative_img, ctx=ctx)\n",
    "    del top_img, bottom_img, bottom_description, bottom_description_drop, negative_img\n",
    "    return top_img_mx, bottom_img_mx, bottom_description_mx, bottom_description_drop_mx, negative_img_mx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(data, imglist, descriptionlist, outfitlist, allbottoms, batch_size, ctx, keep_rate):\n",
    "    random.shuffle(data)\n",
    "    for batch_i in range(0,len(data)//batch_size+1):\n",
    "        start_i = batch_i*batch_size\n",
    "        batch = data[start_i:start_i+batch_size]\n",
    "        yield batch_to_input(batch, imglist, descriptionlist, outfitlist, allbottoms, ctx, keep_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluation_batch_to_input(batch, imglist, descriptionlist, ctx):\n",
    "    top_img = []\n",
    "    bottom_img = []\n",
    "    bottom_description = []\n",
    "    negative_img = []\n",
    "    for instance in batch:\n",
    "        top_img.append(get_img(instance[0], imglist))\n",
    "        bottom_img.append(get_img(instance[2], imglist))\n",
    "        bottom_description.append(descriptionlist[instance[1]]['vector'])\n",
    "        negative_img.append(get_img(instance[3], imglist))\n",
    "    top_img_mx = nd.array(top_img, ctx=ctx)\n",
    "    bottom_img_mx = nd.array(bottom_img, ctx=ctx)\n",
    "    bottom_description_mx = nd.array(bottom_description, ctx=ctx)\n",
    "    negative_img_mx = nd.array(negative_img, ctx=ctx)\n",
    "    del top_img, bottom_img, bottom_description, negative_img\n",
    "    return top_img_mx, bottom_img_mx, bottom_description_mx, negative_img_mx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_evaluation_batches(top, description, bottom, negatives, imglist, descriptionlist, batch_size, ctx):\n",
    "    data = []\n",
    "    for negative in negatives:\n",
    "        data.append([top,description,bottom,negative])\n",
    "    for batch_i in range(0,len(data)//batch_size+1):\n",
    "        start_i = batch_i*batch_size\n",
    "        batch = data[start_i:start_i+batch_size]            \n",
    "        yield evaluation_batch_to_input(batch, imglist, descriptionlist, ctx)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = farm()\n",
    "net.initialize(ctx=ctx,init=init.Xavier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': 0.001, 'clip_gradient': 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(train_data, valid_data, imglist, descriptionlist, outfitlist, allbottoms, net, loss, l2loss, l1loss, trainer, ctx, batch_size, keep_rate, num_epochs, print_batches=None):\n",
    "    \"\"\"Train a network\"\"\"\n",
    "    print(\"Start training on \", ctx)\n",
    "    for epoch in range(num_epochs):\n",
    "        train_rec_loss, train_gen_loss, valid_auc, valid_gen_loss, n = 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "        start = time()\n",
    "        for i, (top_img, bottom_img, bottom_description, bottom_description_drop, negative_img) in enumerate(get_batches(train_data, imglist, descriptionlist, outfitlist, allbottoms, batch_size, ctx, keep_rate)):\n",
    "            with autograd.record():\n",
    "                y_rec_low, y_rec_high, difference_pn, z_mean, z_log_var = net(top_img, bottom_img, negative_img, bottom_description, bottom_description_drop, 'train')\n",
    "                l, l_rec, l_gen = loss(bottom_img, y_rec_low, y_rec_high, difference_pn, z_mean, z_log_var, l2loss, l1loss)\n",
    "            l.backward()\n",
    "            trainer.step(batch_size)\n",
    "            train_rec_loss += l_rec.asscalar()\n",
    "            train_gen_loss += l_gen.asscalar()\n",
    "            n += batch_size\n",
    "            del top_img, bottom_img, bottom_description, bottom_description_drop, negative_img\n",
    "            if print_batches and (i+1) % print_batches == 0:\n",
    "                print(\"Batch %d. Train_Rec_Loss: %f, Train_Gen_Loss: %f\" % (\n",
    "                    n, train_rec_loss/n, train_gen_loss/n\n",
    "                )) \n",
    "                gc.collect()\n",
    "        net.collect_params().save('checkpoint/farm_params_'+str(epoch)+'.dat')\n",
    "        for (top, description, bottom), negatives in valid_data.items():\n",
    "            auc = []\n",
    "            for i, (top_img, bottom_img, bottom_description, negative_img) in enumerate(get_evaluation_batches(top, description, bottom, negatives, imglist, descriptionlist, batch_size, ctx)):  \n",
    "                _, y_rec, difference_pn, _, _ = net(top_img, bottom_img, negative_img, bottom_description, bottom_description, 'test')\n",
    "                l = nd.mean(y_rec.shape[1]*y_rec.shape[2]*y_rec.shape[3]*l2loss(bottom_img,y_rec)) \n",
    "                auc += list(difference_pn.asnumpy())\n",
    "                del top_img, bottom_img, bottom_description, negative_img\n",
    "            valid_gen_loss += l.asscalar()\n",
    "            valid_auc += 1-(np.array(auc) <= 0).sum()/len(auc)\n",
    "        print(\"Epoch %d. Train_Rec_Loss: %.3f, Train_Gen_Loss: %.3f, Valid_AUC: %.3f, Valid_Gen_Loss: %.3f, Time %.1f sec\" % (\n",
    "            epoch, train_rec_loss/len(train_data), train_gen_loss/len(train_data), valid_auc/len(valid_data), valid_gen_loss/len(valid_data), time()-start\n",
    "        ))\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train(train_data, valid_data, imglist, descriptionlist, outfitlist, allbottoms, net, loss, l2loss, l1loss, trainer, ctx, 64, 1.0, 50, print_batches=100)\n",
    "#train(train_data, valid_data, imglist, descriptionlist, outfitlist, alltops, net, loss, l2loss, l1loss, trainer, ctx, 64, 1.0, 50, print_batches=100)#for top recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(imglist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net.collect_params().load('checkpoint/farm_params_'+str(epoch)+'.dat', ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(test_data, imglist, descriptionlist, bottomlist, net, l1loss, ctx, batch_size, output=False):   \n",
    "    test_auc, test_mrr, test_map, test_gen_loss = 0.0, 0.0, 0.0, 0.0\n",
    "    k = 0\n",
    "    for (top, description, bottom), negatives in test_data.items():\n",
    "        auc = []\n",
    "        for i, (top_img, bottom_img, bottom_description, negative_img) in enumerate(get_evaluation_batches(top, description, bottom, negatives, imglist, descriptionlist, batch_size, ctx)):  \n",
    "            _, y_rec, difference_pn, _, _ = net(top_img, bottom_img, negative_img, bottom_description, bottom_description, 'test')\n",
    "            l = nd.mean(y_rec.shape[1]*y_rec.shape[2]*y_rec.shape[3]*l2loss(bottom_img,y_rec))              \n",
    "            auc += list(difference_pn.asnumpy())\n",
    "            del top_img, bottom_img, bottom_description, negative_img\n",
    "        test_gen_loss += l.asscalar()\n",
    "        test_auc += 1-(np.array(auc) <= 0).sum()/len(auc)\n",
    "        test_mrr += 1/((np.array(auc) <= 0).sum()+1)\n",
    "        test_map += 1/((np.array(auc) <= 0).sum()+1)\n",
    "        if output:\n",
    "            record = {}\n",
    "            j = 0\n",
    "            for neg in negatives:\n",
    "                record[neg] = auc[j]\n",
    "                j += 1\n",
    "            record[bottom] = 0.0\n",
    "            record = sorted(record.items(),key=lambda item:item[1],reverse=False)\n",
    "            os.makedirs('output/'+str(k))\n",
    "            with open('output/'+str(k)+'/text.txt','w',encoding='utf-8') as f:\n",
    "                shutil.copyfile('img/'+top+'.jpg','output/'+str(k)+'/'+top+'.jpg')\n",
    "                f.write(top+'\\t'+descriptionlist[description]['text']+'\\n')\n",
    "                j = 0\n",
    "                while j < 10:\n",
    "                    img = record[j][0]\n",
    "                    if img is not bottom:\n",
    "                        shutil.copyfile('img/'+img+'.jpg','output/'+str(k)+'/'+str(j)+'.jpg')\n",
    "                    else:\n",
    "                        shutil.copyfile('img/'+img+'.jpg','output/'+str(k)+'/'+str(j)+'_.jpg')\n",
    "                    des = bottomlist[img]['description']\n",
    "                    f.write(img+'\\t'+descriptionlist[des]['text']+'\\n')\n",
    "                    j += 1\n",
    "            y_rec = y_rec[0].transpose([1,2,0]).asnumpy()\n",
    "            plt.imsave('output/'+str(k)+'/rec.jpg',y_rec)\n",
    "            del record\n",
    "        k += 1\n",
    "    print(\"Test_AUC: %.3f, Test_MRR: %.3f, Test_MAP: %.3f, Test_Gen_Loss: %.3f\" % (\n",
    "        test_auc/len(test_data), test_mrr/len(test_data), test_map/len(test_data), test_gen_loss/len(test_data)\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test(test_data, imglist, descriptionlist, bottomlist, net, l2loss, ctx, 64, True)\n",
    "#test(test_data, imglist, descriptionlist, toplist, net, l2loss, ctx, 64, True)#for top recommendation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
